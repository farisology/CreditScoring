{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Have you asked yourself why am I going to use PCA?**\n",
    "\n",
    "We know from the previous attempts that :\n",
    "- Our model overfits.\n",
    "- There are outliers.\n",
    "- There is some dependancy in between some fo the feautres.\n",
    "\n",
    "**Will PCA solve all of these problems?**\n",
    "\n",
    "*No, PCA will reduce the dimensionality but it doesn't gurantee that it will solve all the issue with the model. The most important part is that PCA is a step in the right direction.*\n",
    "\n",
    "#### Here we start from the point where PCA can be applied \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as se\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('training.csv')\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "# Separating train and test samples by 30 for the testing \n",
    "\n",
    "X = data [['RevolvingUtilizationOfUnsecuredLines', 'age',\n",
    "          'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome',\n",
    "          'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n",
    "          'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n",
    "          'NumberOfDependents']]\n",
    "y = data [['SeriousDlqin2yrs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I hope you know that there are multiple ways in which we can reduce the dimensions of our feature space. In general they fall in two categories:*\n",
    "\n",
    "- Feature Elemination.\n",
    "- Feature Extraction.\n",
    "\n",
    "When we eleminate feautres we basically remove/drop/get rid of some features. It is a simple approach and easy to implement, but the drawback is that we gain no information from such method. If you drop them then you have exclude said features.\n",
    "\n",
    "Extracting feautres however is creating new varibales in a way and order that remove dependency between our features. The new feautres are engineered in a way that by how good are they in predicting our dependant variable.\n",
    "\n",
    "**Where does the deminsionality reduction come to play?\"**\n",
    "\n",
    "In a nut shell we re-produce our engineerd features (features extraction) and then select only the feautres that are import and drop the least importans ones. In fact our new feautres are a combinations of the old feautres, so even when we drop the least important engineered features we still preserve information from the old feautres.\n",
    "\n",
    "**The following questions determine if you need to use PCA:**\n",
    "\n",
    "- Do you want to reduce the number of variables, but arenâ€™t able to identify variables to completely remove from consideration?\n",
    "- Do you want to ensure your variables are independent of one another?\n",
    "- Are you comfortable making your independent variables less interpretable?\n",
    "\n",
    "If you answered all **yes** then PCA is the go to, if you answered the last question with **no** then maybe you should look at something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does PCA work?\n",
    "\n",
    "- **Calculate a matrix that summarizes the relations between our feautres.**\n",
    "- **Separate this matrix into two components, direction and magnitude.**\n",
    "- **Transform original data to align with the important directions**\n",
    "\n",
    "[Visual Explanation for PCA](http://setosa.io/ev/principal-component-analysis/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will follow the steps:\n",
    "    - Create a pipline versioning two copies of the dataset (scaled and unscaled).\n",
    "    - Use a classifier to be trained in each sample.\n",
    "    - Plot the results of each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faris/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/faris/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction accuracy for the normal test dataset with PCA\n",
      "93.38%\n",
      "\n",
      "\n",
      "Prediction accuracy for the standardized test dataset with PCA\n",
      "93.32%\n",
      "\n",
      "\n",
      "PC 1 without scaling:\n",
      " [ 1.23083353e-04  3.31421345e-05 -2.31908924e-06 -7.24281787e-04\n",
      "  9.99999729e-01  2.73775781e-05 -2.78386658e-06  8.34464585e-06\n",
      " -2.43504700e-06  4.24402195e-06]\n",
      "\n",
      "PC 1 with scaling:\n",
      " [-5.32587021e-04 -5.88646804e-02  5.72239188e-01 -1.39046038e-02\n",
      " -1.39087397e-02 -7.81773124e-02  5.74185996e-01 -5.38244098e-02\n",
      "  5.74393171e-01 -8.02215652e-03]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "FIG_SIZE = (10, 7)\n",
    "\n",
    "\n",
    "\n",
    "# Make a train/test split using 30% test size\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=RANDOM_STATE)\n",
    "\n",
    "# Fit to data and predict using pipelined GNB and PCA.\n",
    "unscaled_clf = make_pipeline(PCA(n_components=2), GaussianNB())\n",
    "unscaled_clf.fit(X_train, y_train)\n",
    "pred_test = unscaled_clf.predict(X_test)\n",
    "\n",
    "# Fit to data and predict using pipelined scaling, GNB and PCA.\n",
    "std_clf = make_pipeline(StandardScaler(), PCA(n_components=2), GaussianNB())\n",
    "std_clf.fit(X_train, y_train)\n",
    "pred_test_std = std_clf.predict(X_test)\n",
    "\n",
    "# Show prediction accuracies in scaled and unscaled data.\n",
    "print('\\nPrediction accuracy for the normal test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test)))\n",
    "\n",
    "print('\\nPrediction accuracy for the standardized test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_std)))\n",
    "\n",
    "# Extract PCA from pipeline\n",
    "pca = unscaled_clf.named_steps['pca']\n",
    "pca_std = std_clf.named_steps['pca']\n",
    "\n",
    "# Show first principal componenets\n",
    "print('\\nPC 1 without scaling:\\n', pca.components_[0])\n",
    "print('\\nPC 1 with scaling:\\n', pca_std.components_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
